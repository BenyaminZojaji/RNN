{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "123_g3AZuDe1cFgfoSFgo9l4d48o3rnFR",
      "authorship_tag": "ABX9TyNu9X01iCsJhe1WfLCX+B3n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XB3V37-ugnnT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, LSTM, GRU\n",
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read csv file\n",
        "def read_csv(file_name):\n",
        "  data_frame = pd.read_csv(file_name)\n",
        "  X = np.array(data_frame[\"sentence\"])\n",
        "  Y = np.array(data_frame[\"label\"], dtype=int) # labels are integer\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "p4BjP2j6hKuq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_csv(\"/content/drive/MyDrive/Dataset/Emoji_Text_Classification/train.csv\")\n",
        "X_test, Y_test = read_csv(\"/content/drive/MyDrive/Dataset/Emoji_Text_Classification/test.csv\")"
      ],
      "metadata": {
        "id": "Gcad7RTlhlAe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get max length of sentences\n",
        "max_len = len(max(X_train, key=len).split(\" \"))\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a709767iRYT",
        "outputId": "dd3095dc-2f69-4aa9-8320-886887cc024a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace labels with related emoji\n",
        "def label_to_emoji(label):\n",
        "    emojies = [\"â¤ï¸\", \"ðŸ\", \"ðŸ˜„\", \"ðŸ˜ž\", \"ðŸ´\"]\n",
        "    return emojies[label]\n",
        "\n",
        "index = 10\n",
        "print(X_train[index], label_to_emoji(Y_train[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2bLb-ITiU_m",
        "outputId": "42b61fb4-cfab-4c9a-924b-95df4bb435cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she did not answer my text  ðŸ˜ž\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of sentence in each class\n",
        "unique, counts = np.unique(Y_train, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMaQCVSUiYpf",
        "outputId": "3fb01eb7-59e3-44ff-e9ec-5b7b83a6d2fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 22, 1: 19, 2: 38, 3: 36, 4: 17}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emojifier-V1"
      ],
      "metadata": {
        "id": "vkC69-h-iliz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one hot\n",
        "num_classes = len(np.unique(Y_train))\n",
        "\n",
        "Y_train_oh = tf.keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test_oh = tf.keras.utils.to_categorical(Y_test, num_classes)"
      ],
      "metadata": {
        "id": "dP9DB0ISib1k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 5\n",
        "print(Y_train[index], \"is converted into one hot\", Y_train_oh[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd4JpWH9it_Q",
        "outputId": "5645ea67-ae67-4146-bb02-22bcfae5cd65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 is converted into one hot [1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download feature vectors and extract\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d glov.6B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6VgxBBKixTd",
        "outputId": "d0b118c0-95e9-48c6-d2ea-1f6ee8e839f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-24 12:10:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-11-24 12:10:12--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-11-24 12:10:12--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zipâ€™\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 40s  \n",
            "\n",
            "2022-11-24 12:12:53 (5.13 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read feature vectors and save them\n",
        "def read_glov_vectors(glove_file):\n",
        "  f = open(glove_file, encoding=\"utf8\")\n",
        "  words = set()\n",
        "  words_to_vec = dict()\n",
        "  for line in f:\n",
        "    line = line.strip().split()\n",
        "    word = line[0]\n",
        "    vec = line[1:]\n",
        "    words.add(word)\n",
        "    words_to_vec[word] = np.array(vec, dtype=np.float64)\n",
        "  return words_to_vec"
      ],
      "metadata": {
        "id": "spOcuL35i7wn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_vec = read_glov_vectors(\"/content/glov.6B/glove.6B.50d.txt\")\n",
        "\n",
        "# Test the output of read_glov_vectors function\n",
        "words_to_vec[\"hello\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN1oyyRMjA8f",
        "outputId": "1e5569b9-4498-41f3-c697-7fed38dac117"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.38497 ,  0.80092 ,  0.064106, -0.28355 , -0.026759, -0.34532 ,\n",
              "       -0.64253 , -0.11729 , -0.33257 ,  0.55243 , -0.087813,  0.9035  ,\n",
              "        0.47102 ,  0.56657 ,  0.6985  , -0.35229 , -0.86542 ,  0.90573 ,\n",
              "        0.03576 , -0.071705, -0.12327 ,  0.54923 ,  0.47005 ,  0.35572 ,\n",
              "        1.2611  , -0.67581 , -0.94983 ,  0.68666 ,  0.3871  , -1.3492  ,\n",
              "        0.63512 ,  0.46416 , -0.48814 ,  0.83827 , -0.9246  , -0.33722 ,\n",
              "        0.53741 , -1.0616  , -0.081403, -0.67111 ,  0.30923 , -0.3923  ,\n",
              "       -0.55002 , -0.68827 ,  0.58049 , -0.11626 ,  0.013139, -0.57654 ,\n",
              "        0.048833,  0.67204 ])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Convert sentences to the average of the word vectors\n",
        "def sentence_to_avg(sentence):\n",
        "  words = sentence.lower().split() # Convert uppercase to lowercase\n",
        "  sum_vectors = np.zeros((50, ))\n",
        "  for w in words:\n",
        "    sum_vectors += words_to_vec[w]\n",
        "  avg_vectors = sum_vectors / len(words)\n",
        "  return avg_vectors"
      ],
      "metadata": {
        "id": "yk1hp7lPjFz3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentence_to_avg function\n",
        "sentence_to_avg(\"Pasta is my favorite food\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQary3yGjIoI",
        "outputId": "e7dc7f85-3763-48f7-e9aa-0ad7e66b5277"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.242832  ,  0.370774  , -0.524396  ,  0.018644  ,  0.568756  ,\n",
              "        0.0219878 , -0.48206322, -0.152204  ,  0.235412  ,  0.1979466 ,\n",
              "       -0.178818  ,  0.3203976 ,  0.3379962 ,  0.1399654 ,  0.56775044,\n",
              "        0.118648  , -0.04531252,  0.335416  ,  0.149832  , -0.522814  ,\n",
              "        0.095746  , -0.0468764 ,  0.5508066 ,  0.39369132,  0.275182  ,\n",
              "       -1.275018  , -0.76076   ,  0.449102  ,  0.7542772 , -0.2332608 ,\n",
              "        2.82554   ,  0.287742  , -0.325976  ,  0.608572  , -0.020543  ,\n",
              "        0.286476  , -0.24984   ,  0.899408  ,  0.38995   , -0.270266  ,\n",
              "        0.3004734 ,  0.315962  , -0.2408782 ,  0.1586226 ,  0.5400462 ,\n",
              "        0.412066  , -0.1657008 , -0.253566  ,  0.3091806 ,  0.371192  ])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the average of all sentences\n",
        "X_train_avg = []\n",
        "for i in range(X_train.shape[0]):\n",
        "  X_train_avg.append(sentence_to_avg(X_train[i]))\n",
        "\n",
        "X_train_avg = np.array(X_train_avg)\n",
        "\n",
        "X_train_avg.shape, Y_train_oh.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjMH_puMjJ7A",
        "outputId": "23bc06a2-f5c8-4cde-a712-cd39b8636993"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((132, 50), (132, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model(using perceptron)\n",
        "class EmojiNet_V1(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense = Dense(num_classes, input_shape=(50,), activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mN5xfu6xjMCU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and fit the model\n",
        "model = EmojiNet_V1()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_avg, Y_train_oh, epochs=400, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqg5lblPjQtd",
        "outputId": "962275c2-02a2-4991-a4e1-8b50ab16c634"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "5/5 [==============================] - 3s 5ms/step - loss: 1.7831 - accuracy: 0.1591\n",
            "Epoch 2/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7443 - accuracy: 0.1667\n",
            "Epoch 3/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.7095 - accuracy: 0.1894\n",
            "Epoch 4/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6809 - accuracy: 0.2197\n",
            "Epoch 5/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6549 - accuracy: 0.2348\n",
            "Epoch 6/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6328 - accuracy: 0.2576\n",
            "Epoch 7/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6126 - accuracy: 0.2955\n",
            "Epoch 8/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5950 - accuracy: 0.3106\n",
            "Epoch 9/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5790 - accuracy: 0.3258\n",
            "Epoch 10/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5651 - accuracy: 0.3561\n",
            "Epoch 11/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5501 - accuracy: 0.3561\n",
            "Epoch 12/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5383 - accuracy: 0.3561\n",
            "Epoch 13/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5260 - accuracy: 0.3561\n",
            "Epoch 14/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5157 - accuracy: 0.3409\n",
            "Epoch 15/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5056 - accuracy: 0.3409\n",
            "Epoch 16/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4962 - accuracy: 0.3561\n",
            "Epoch 17/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4868 - accuracy: 0.3636\n",
            "Epoch 18/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4786 - accuracy: 0.3636\n",
            "Epoch 19/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4697 - accuracy: 0.3712\n",
            "Epoch 20/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4612 - accuracy: 0.3712\n",
            "Epoch 21/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4527 - accuracy: 0.3636\n",
            "Epoch 22/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4444 - accuracy: 0.3712\n",
            "Epoch 23/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4363 - accuracy: 0.3788\n",
            "Epoch 24/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4286 - accuracy: 0.3864\n",
            "Epoch 25/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4208 - accuracy: 0.3864\n",
            "Epoch 26/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4131 - accuracy: 0.3864\n",
            "Epoch 27/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4055 - accuracy: 0.4015\n",
            "Epoch 28/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3984 - accuracy: 0.4015\n",
            "Epoch 29/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3908 - accuracy: 0.4015\n",
            "Epoch 30/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3837 - accuracy: 0.4091\n",
            "Epoch 31/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3761 - accuracy: 0.4015\n",
            "Epoch 32/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3697 - accuracy: 0.4242\n",
            "Epoch 33/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3629 - accuracy: 0.4167\n",
            "Epoch 34/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3559 - accuracy: 0.4091\n",
            "Epoch 35/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3490 - accuracy: 0.4242\n",
            "Epoch 36/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3414 - accuracy: 0.4242\n",
            "Epoch 37/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3346 - accuracy: 0.4167\n",
            "Epoch 38/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3284 - accuracy: 0.4015\n",
            "Epoch 39/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3226 - accuracy: 0.4091\n",
            "Epoch 40/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3168 - accuracy: 0.4091\n",
            "Epoch 41/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3093 - accuracy: 0.4318\n",
            "Epoch 42/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3019 - accuracy: 0.4470\n",
            "Epoch 43/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2940 - accuracy: 0.4470\n",
            "Epoch 44/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2879 - accuracy: 0.4318\n",
            "Epoch 45/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2809 - accuracy: 0.4545\n",
            "Epoch 46/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2749 - accuracy: 0.4621\n",
            "Epoch 47/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2690 - accuracy: 0.4848\n",
            "Epoch 48/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2625 - accuracy: 0.4848\n",
            "Epoch 49/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2557 - accuracy: 0.5000\n",
            "Epoch 50/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.4924\n",
            "Epoch 51/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2433 - accuracy: 0.5000\n",
            "Epoch 52/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2378 - accuracy: 0.5152\n",
            "Epoch 53/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2320 - accuracy: 0.5152\n",
            "Epoch 54/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2263 - accuracy: 0.5152\n",
            "Epoch 55/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2206 - accuracy: 0.5455\n",
            "Epoch 56/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2153 - accuracy: 0.5455\n",
            "Epoch 57/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2102 - accuracy: 0.5455\n",
            "Epoch 58/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2043 - accuracy: 0.5455\n",
            "Epoch 59/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1990 - accuracy: 0.5606\n",
            "Epoch 60/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1934 - accuracy: 0.5682\n",
            "Epoch 61/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1883 - accuracy: 0.5682\n",
            "Epoch 62/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1829 - accuracy: 0.5682\n",
            "Epoch 63/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1779 - accuracy: 0.5682\n",
            "Epoch 64/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1722 - accuracy: 0.5758\n",
            "Epoch 65/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1676 - accuracy: 0.5909\n",
            "Epoch 66/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1624 - accuracy: 0.5985\n",
            "Epoch 67/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1572 - accuracy: 0.5985\n",
            "Epoch 68/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1519 - accuracy: 0.6061\n",
            "Epoch 69/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1467 - accuracy: 0.6061\n",
            "Epoch 70/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1423 - accuracy: 0.6061\n",
            "Epoch 71/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1375 - accuracy: 0.6061\n",
            "Epoch 72/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1327 - accuracy: 0.6136\n",
            "Epoch 73/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1285 - accuracy: 0.6212\n",
            "Epoch 74/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1238 - accuracy: 0.6136\n",
            "Epoch 75/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1191 - accuracy: 0.6061\n",
            "Epoch 76/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.6061\n",
            "Epoch 77/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1112 - accuracy: 0.6061\n",
            "Epoch 78/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1067 - accuracy: 0.6136\n",
            "Epoch 79/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1024 - accuracy: 0.6061\n",
            "Epoch 80/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0979 - accuracy: 0.6136\n",
            "Epoch 81/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0937 - accuracy: 0.6439\n",
            "Epoch 82/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0894 - accuracy: 0.6439\n",
            "Epoch 83/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.6515\n",
            "Epoch 84/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0804 - accuracy: 0.6515\n",
            "Epoch 85/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.6515\n",
            "Epoch 86/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0727 - accuracy: 0.6515\n",
            "Epoch 87/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0684 - accuracy: 0.6515\n",
            "Epoch 88/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.6667\n",
            "Epoch 89/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.6742\n",
            "Epoch 90/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0576 - accuracy: 0.6818\n",
            "Epoch 91/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0541 - accuracy: 0.6742\n",
            "Epoch 92/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0504 - accuracy: 0.6742\n",
            "Epoch 93/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.6667\n",
            "Epoch 94/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0432 - accuracy: 0.6667\n",
            "Epoch 95/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0393 - accuracy: 0.6742\n",
            "Epoch 96/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0356 - accuracy: 0.6742\n",
            "Epoch 97/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0317 - accuracy: 0.6742\n",
            "Epoch 98/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0285 - accuracy: 0.6818\n",
            "Epoch 99/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.6742\n",
            "Epoch 100/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0203 - accuracy: 0.6742\n",
            "Epoch 101/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0177 - accuracy: 0.6742\n",
            "Epoch 102/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0147 - accuracy: 0.6742\n",
            "Epoch 103/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0107 - accuracy: 0.6667\n",
            "Epoch 104/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0081 - accuracy: 0.6667\n",
            "Epoch 105/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0047 - accuracy: 0.6818\n",
            "Epoch 106/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0017 - accuracy: 0.6742\n",
            "Epoch 107/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9990 - accuracy: 0.6667\n",
            "Epoch 108/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.6742\n",
            "Epoch 109/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9921 - accuracy: 0.6742\n",
            "Epoch 110/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9883 - accuracy: 0.6818\n",
            "Epoch 111/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9847 - accuracy: 0.6818\n",
            "Epoch 112/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9807 - accuracy: 0.6894\n",
            "Epoch 113/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9773 - accuracy: 0.6818\n",
            "Epoch 114/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9741 - accuracy: 0.6818\n",
            "Epoch 115/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9711 - accuracy: 0.6894\n",
            "Epoch 116/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.6894\n",
            "Epoch 117/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9659 - accuracy: 0.6970\n",
            "Epoch 118/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9636 - accuracy: 0.6970\n",
            "Epoch 119/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9604 - accuracy: 0.6970\n",
            "Epoch 120/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9578 - accuracy: 0.7045\n",
            "Epoch 121/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9545 - accuracy: 0.6970\n",
            "Epoch 122/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9513 - accuracy: 0.7045\n",
            "Epoch 123/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.7045\n",
            "Epoch 124/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9454 - accuracy: 0.6970\n",
            "Epoch 125/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9424 - accuracy: 0.7045\n",
            "Epoch 126/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.7045\n",
            "Epoch 127/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9364 - accuracy: 0.6970\n",
            "Epoch 128/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9336 - accuracy: 0.7045\n",
            "Epoch 129/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9320 - accuracy: 0.7045\n",
            "Epoch 130/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9298 - accuracy: 0.7045\n",
            "Epoch 131/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9272 - accuracy: 0.7121\n",
            "Epoch 132/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.7121\n",
            "Epoch 133/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9223 - accuracy: 0.7121\n",
            "Epoch 134/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9192 - accuracy: 0.7121\n",
            "Epoch 135/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9162 - accuracy: 0.7121\n",
            "Epoch 136/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9127 - accuracy: 0.7121\n",
            "Epoch 137/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9095 - accuracy: 0.7197\n",
            "Epoch 138/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9069 - accuracy: 0.7197\n",
            "Epoch 139/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9045 - accuracy: 0.7121\n",
            "Epoch 140/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9019 - accuracy: 0.7197\n",
            "Epoch 141/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8993 - accuracy: 0.7197\n",
            "Epoch 142/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8968 - accuracy: 0.7197\n",
            "Epoch 143/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8944 - accuracy: 0.7121\n",
            "Epoch 144/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8920 - accuracy: 0.7197\n",
            "Epoch 145/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8893 - accuracy: 0.7197\n",
            "Epoch 146/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.7197\n",
            "Epoch 147/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8846 - accuracy: 0.7121\n",
            "Epoch 148/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.7273\n",
            "Epoch 149/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8798 - accuracy: 0.7197\n",
            "Epoch 150/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8774 - accuracy: 0.7273\n",
            "Epoch 151/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.7273\n",
            "Epoch 152/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8731 - accuracy: 0.7121\n",
            "Epoch 153/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8708 - accuracy: 0.7121\n",
            "Epoch 154/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.7197\n",
            "Epoch 155/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8664 - accuracy: 0.7197\n",
            "Epoch 156/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8643 - accuracy: 0.7273\n",
            "Epoch 157/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8618 - accuracy: 0.7273\n",
            "Epoch 158/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.7273\n",
            "Epoch 159/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.7348\n",
            "Epoch 160/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8548 - accuracy: 0.7500\n",
            "Epoch 161/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.7500\n",
            "Epoch 162/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8503 - accuracy: 0.7500\n",
            "Epoch 163/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8480 - accuracy: 0.7348\n",
            "Epoch 164/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8461 - accuracy: 0.7273\n",
            "Epoch 165/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8441 - accuracy: 0.7273\n",
            "Epoch 166/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8427 - accuracy: 0.7273\n",
            "Epoch 167/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8405 - accuracy: 0.7273\n",
            "Epoch 168/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.7273\n",
            "Epoch 169/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8358 - accuracy: 0.7273\n",
            "Epoch 170/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8337 - accuracy: 0.7424\n",
            "Epoch 171/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.7500\n",
            "Epoch 172/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8294 - accuracy: 0.7500\n",
            "Epoch 173/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.7424\n",
            "Epoch 174/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8257 - accuracy: 0.7500\n",
            "Epoch 175/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.7500\n",
            "Epoch 176/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.7576\n",
            "Epoch 177/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.7500\n",
            "Epoch 178/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.7576\n",
            "Epoch 179/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8163 - accuracy: 0.7576\n",
            "Epoch 180/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8147 - accuracy: 0.7424\n",
            "Epoch 181/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8128 - accuracy: 0.7500\n",
            "Epoch 182/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8114 - accuracy: 0.7500\n",
            "Epoch 183/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.7500\n",
            "Epoch 184/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8066 - accuracy: 0.7500\n",
            "Epoch 185/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.7500\n",
            "Epoch 186/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.7576\n",
            "Epoch 187/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8008 - accuracy: 0.7652\n",
            "Epoch 188/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7991 - accuracy: 0.7576\n",
            "Epoch 189/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7969 - accuracy: 0.7576\n",
            "Epoch 190/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.7500\n",
            "Epoch 191/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7941 - accuracy: 0.7576\n",
            "Epoch 192/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.7500\n",
            "Epoch 193/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7911 - accuracy: 0.7500\n",
            "Epoch 194/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7891 - accuracy: 0.7500\n",
            "Epoch 195/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7874 - accuracy: 0.7500\n",
            "Epoch 196/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7855 - accuracy: 0.7500\n",
            "Epoch 197/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7838 - accuracy: 0.7500\n",
            "Epoch 198/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.7500\n",
            "Epoch 199/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.7652\n",
            "Epoch 200/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7777 - accuracy: 0.7576\n",
            "Epoch 201/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7760 - accuracy: 0.7576\n",
            "Epoch 202/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.7576\n",
            "Epoch 203/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7733 - accuracy: 0.7727\n",
            "Epoch 204/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7714 - accuracy: 0.7652\n",
            "Epoch 205/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7700 - accuracy: 0.7576\n",
            "Epoch 206/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7685 - accuracy: 0.7652\n",
            "Epoch 207/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.7652\n",
            "Epoch 208/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7649 - accuracy: 0.7652\n",
            "Epoch 209/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7652\n",
            "Epoch 210/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7613 - accuracy: 0.7652\n",
            "Epoch 211/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.7652\n",
            "Epoch 212/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7579 - accuracy: 0.7652\n",
            "Epoch 213/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.7652\n",
            "Epoch 214/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7543 - accuracy: 0.7652\n",
            "Epoch 215/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7652\n",
            "Epoch 216/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7513 - accuracy: 0.7727\n",
            "Epoch 217/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.7727\n",
            "Epoch 218/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7482 - accuracy: 0.7803\n",
            "Epoch 219/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7467 - accuracy: 0.7803\n",
            "Epoch 220/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.7803\n",
            "Epoch 221/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7727\n",
            "Epoch 222/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7727\n",
            "Epoch 223/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.7727\n",
            "Epoch 224/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.7727\n",
            "Epoch 225/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.7727\n",
            "Epoch 226/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.7803\n",
            "Epoch 227/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.7803\n",
            "Epoch 228/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.7803\n",
            "Epoch 229/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7320 - accuracy: 0.7803\n",
            "Epoch 230/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7306 - accuracy: 0.7803\n",
            "Epoch 231/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.7727\n",
            "Epoch 232/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7277 - accuracy: 0.7727\n",
            "Epoch 233/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.7803\n",
            "Epoch 234/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.7803\n",
            "Epoch 235/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.7803\n",
            "Epoch 236/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7218 - accuracy: 0.7879\n",
            "Epoch 237/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7205 - accuracy: 0.7879\n",
            "Epoch 238/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7879\n",
            "Epoch 239/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7176 - accuracy: 0.7879\n",
            "Epoch 240/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7169 - accuracy: 0.7955\n",
            "Epoch 241/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.7955\n",
            "Epoch 242/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.7955\n",
            "Epoch 243/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.7955\n",
            "Epoch 244/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.7955\n",
            "Epoch 245/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7102 - accuracy: 0.7879\n",
            "Epoch 246/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.7955\n",
            "Epoch 247/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7078 - accuracy: 0.7955\n",
            "Epoch 248/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.7955\n",
            "Epoch 249/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.7955\n",
            "Epoch 250/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.7955\n",
            "Epoch 251/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7955\n",
            "Epoch 252/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.8030\n",
            "Epoch 253/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.7955\n",
            "Epoch 254/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.8030\n",
            "Epoch 255/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6971 - accuracy: 0.8030\n",
            "Epoch 256/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.8030\n",
            "Epoch 257/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.8106\n",
            "Epoch 258/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.8030\n",
            "Epoch 259/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.7955\n",
            "Epoch 260/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.8030\n",
            "Epoch 261/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6899 - accuracy: 0.8030\n",
            "Epoch 262/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.8106\n",
            "Epoch 263/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.8106\n",
            "Epoch 264/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.8106\n",
            "Epoch 265/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.7955\n",
            "Epoch 266/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.7955\n",
            "Epoch 267/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7955\n",
            "Epoch 268/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.7955\n",
            "Epoch 269/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.7955\n",
            "Epoch 270/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.7955\n",
            "Epoch 271/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.7879\n",
            "Epoch 272/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.7879\n",
            "Epoch 273/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.7879\n",
            "Epoch 274/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7879\n",
            "Epoch 275/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.7955\n",
            "Epoch 276/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.7955\n",
            "Epoch 277/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7955\n",
            "Epoch 278/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7955\n",
            "Epoch 279/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.7955\n",
            "Epoch 280/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.7955\n",
            "Epoch 281/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7955\n",
            "Epoch 282/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.8030\n",
            "Epoch 283/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.8030\n",
            "Epoch 284/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.8030\n",
            "Epoch 285/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.8030\n",
            "Epoch 286/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.8030\n",
            "Epoch 287/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.8030\n",
            "Epoch 288/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.8182\n",
            "Epoch 289/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.8182\n",
            "Epoch 290/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.8030\n",
            "Epoch 291/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.8030\n",
            "Epoch 292/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.8106\n",
            "Epoch 293/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.8106\n",
            "Epoch 294/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.8106\n",
            "Epoch 295/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.8106\n",
            "Epoch 296/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.8106\n",
            "Epoch 297/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.8106\n",
            "Epoch 298/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.8106\n",
            "Epoch 299/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.8106\n",
            "Epoch 300/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.8106\n",
            "Epoch 301/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.8182\n",
            "Epoch 302/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.8182\n",
            "Epoch 303/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.8182\n",
            "Epoch 304/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.8182\n",
            "Epoch 305/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.8182\n",
            "Epoch 306/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.8106\n",
            "Epoch 307/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.8030\n",
            "Epoch 308/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.8106\n",
            "Epoch 309/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.8258\n",
            "Epoch 310/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.8182\n",
            "Epoch 311/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.8182\n",
            "Epoch 312/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.8182\n",
            "Epoch 313/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.8182\n",
            "Epoch 314/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.8182\n",
            "Epoch 315/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.8333\n",
            "Epoch 316/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.8333\n",
            "Epoch 317/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.8106\n",
            "Epoch 318/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.8106\n",
            "Epoch 319/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.8182\n",
            "Epoch 320/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6242 - accuracy: 0.8182\n",
            "Epoch 321/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.8182\n",
            "Epoch 322/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.8258\n",
            "Epoch 323/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.8258\n",
            "Epoch 324/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.8333\n",
            "Epoch 325/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.8258\n",
            "Epoch 326/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.8258\n",
            "Epoch 327/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.8258\n",
            "Epoch 328/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6173 - accuracy: 0.8258\n",
            "Epoch 329/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.8258\n",
            "Epoch 330/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.8258\n",
            "Epoch 331/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.8258\n",
            "Epoch 332/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.8258\n",
            "Epoch 333/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.8258\n",
            "Epoch 334/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.8258\n",
            "Epoch 335/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.8258\n",
            "Epoch 336/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.8258\n",
            "Epoch 337/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.8258\n",
            "Epoch 338/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.8258\n",
            "Epoch 339/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.8258\n",
            "Epoch 340/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.8333\n",
            "Epoch 341/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.8333\n",
            "Epoch 342/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.8258\n",
            "Epoch 343/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.8182\n",
            "Epoch 344/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.8258\n",
            "Epoch 345/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.8258\n",
            "Epoch 346/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.8258\n",
            "Epoch 347/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.8182\n",
            "Epoch 348/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.8182\n",
            "Epoch 349/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.8258\n",
            "Epoch 350/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.8258\n",
            "Epoch 351/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.8182\n",
            "Epoch 352/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.8182\n",
            "Epoch 353/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.8106\n",
            "Epoch 354/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.8106\n",
            "Epoch 355/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.8106\n",
            "Epoch 356/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.8258\n",
            "Epoch 357/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.8258\n",
            "Epoch 358/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8258\n",
            "Epoch 359/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.8333\n",
            "Epoch 360/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.8333\n",
            "Epoch 361/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.8409\n",
            "Epoch 362/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8485\n",
            "Epoch 363/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.8409\n",
            "Epoch 364/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.8333\n",
            "Epoch 365/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8409\n",
            "Epoch 366/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.8409\n",
            "Epoch 367/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.8333\n",
            "Epoch 368/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.8333\n",
            "Epoch 369/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.8258\n",
            "Epoch 370/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.8409\n",
            "Epoch 371/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.8409\n",
            "Epoch 372/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.8409\n",
            "Epoch 373/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.8409\n",
            "Epoch 374/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.8409\n",
            "Epoch 375/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.8409\n",
            "Epoch 376/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.8409\n",
            "Epoch 377/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.8485\n",
            "Epoch 378/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.8485\n",
            "Epoch 379/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.8485\n",
            "Epoch 380/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.8485\n",
            "Epoch 381/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.8485\n",
            "Epoch 382/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.8485\n",
            "Epoch 383/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.8409\n",
            "Epoch 384/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8409\n",
            "Epoch 385/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.8485\n",
            "Epoch 386/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.8485\n",
            "Epoch 387/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.8485\n",
            "Epoch 388/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.8485\n",
            "Epoch 389/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8485\n",
            "Epoch 390/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.8561\n",
            "Epoch 391/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8485\n",
            "Epoch 392/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.8485\n",
            "Epoch 393/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.8485\n",
            "Epoch 394/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8485\n",
            "Epoch 395/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.8561\n",
            "Epoch 396/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.8561\n",
            "Epoch 397/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.8561\n",
            "Epoch 398/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.8561\n",
            "Epoch 399/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.8636\n",
            "Epoch 400/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8561\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f25a4419cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "X_test_avg = []\n",
        "for i in range(X_test.shape[0]):\n",
        "    X_test_avg.append(sentence_to_avg(X_test[i]))\n",
        "\n",
        "X_test_avg = np.array(X_test_avg)\n",
        "model.evaluate(X_test_avg, Y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvwjx_D8jTa4",
        "outputId": "fc39866b-ee17-4f06-d68b-7c1bbefe7330"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6318 - accuracy: 0.8214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6317513585090637, 0.8214285969734192]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "X_me = np.array([\"not happy\", \"not sad\", \"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy and funny\"])\n",
        "# Y_me = np.array([[2], [0], [0], [2], [1], [4], [3]])\n",
        "X_me_avg = []\n",
        "\n",
        "for x in X_me:\n",
        "    X_me_avg.append(sentence_to_avg(x))\n",
        "\n",
        "X_me_avg = np.array(X_me_avg)\n",
        "pred = model.predict(X_me_avg)\n",
        "\n",
        "for i in range(X_me.shape[0]):\n",
        "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tp8nyi0jT7J",
        "outputId": "292e1f3d-6317-45e7-8572-96993fb37172"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "not happy ðŸ˜ž\n",
            "not sad ðŸ˜ž\n",
            "i adore you â¤ï¸\n",
            "i love you â¤ï¸\n",
            "funny lol ðŸ˜„\n",
            "lets play with a ball ðŸ\n",
            "food is ready ðŸ´\n",
            "not feeling happy and funny ðŸ˜„\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emojifier-V2: Using RNNs"
      ],
      "metadata": {
        "id": "C3MhEqE_jcEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class EmojiNet_V2(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lstm_1 = LSTM(512, return_sequences=True)\n",
        "        self.dropout_1 = Dropout(0.3)\n",
        "        self.lstm_2 = LSTM(256, return_sequences=True)\n",
        "        self.lstm_3 = LSTM(4096)\n",
        "        self.dropout_2 = Dropout(0.3)\n",
        "        self.dense = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.lstm_1(x)\n",
        "        x = self.dropout_1(x)\n",
        "        # x = self.lstm_2(x)\n",
        "        # x = self.dropout_2(x)\n",
        "        x = self.lstm_3(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6hGhPcRfjZMm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model = EmojiNet_V2()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Juy_euoZjlBr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the size of all sentences to max_len\n",
        "def convert_sentences_to_embeddings(X):\n",
        "    emb_dim = words_to_vec[\"cucumber\"].shape[0]  # define dimensionality of your GloVe word vectors (= 50)\n",
        "    emb_matrix = np.zeros((X.shape[0], max_len, emb_dim))\n",
        "    for i in range(X.shape[0]):\n",
        "        words = X[i].lower().split()\n",
        "        for j in range(len(words)):\n",
        "            emb_matrix[i, j, :] = words_to_vec[words[j]]\n",
        "    return emb_matrix"
      ],
      "metadata": {
        "id": "E1kiVZYTjlmG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test convert_sentences_to_embeddings function\n",
        "X_me = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "print(X_me)\n",
        "print(convert_sentences_to_embeddings(X_me))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLXFBAL_jsez",
        "outputId": "1745f050-8ccb-4092-877e-c49fe88fb5a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "[[[-0.014547 -0.20208  -0.75278  ... -0.13429   0.21133   1.5368  ]\n",
            "  [-0.54289   0.053743 -0.46978  ...  0.20745  -0.074958  0.080575]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.30423  -0.24405   1.0303   ... -0.43296  -0.096168  0.43463 ]\n",
            "  [-0.73571   0.19937  -0.89408  ... -0.075279 -0.44448   0.47437 ]\n",
            "  [-1.9327    1.0421   -0.78515  ...  0.55667  -0.70315   0.17157 ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.47222  -0.44545  -0.51833  ...  0.34932   0.33934   0.25499 ]\n",
            "  [ 0.6185    0.64254  -0.46552  ... -0.27557   0.30899   0.48497 ]\n",
            "  [ 0.36825  -0.20512   0.36656  ...  0.40331  -0.47358   0.54165 ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run convert_sentences_to_embeddings function for training data \n",
        "X_train_embs =convert_sentences_to_embeddings(X_train)\n",
        "X_train_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGFxgWyojwUO",
        "outputId": "92394055-c1e9-4462-c6af-17907da64962"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 10, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_embs, Y_train_oh, epochs=200, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "y827gKhAjy86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "X_test_embs = convert_sentences_to_embeddings(X_test)\n",
        "print(X_test_embs.shape)\n",
        "model.evaluate(X_test_embs, Y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZofCixEjzUl",
        "outputId": "984a3a89-3654-4e2a-c60c-6dcca6b9df01"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56, 10, 50)\n",
            "2/2 [==============================] - 1s 46ms/step - loss: 0.7334 - accuracy: 0.8393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7334117889404297, 0.8392857313156128]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "X_me = np.array([\"not happy\", \"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\", \"not feeling happy and funny\"])\n",
        "#Y_me = np.array([[2], [0], [0], [2], [1], [4], [3]])\n",
        "X_me_embed = convert_sentences_to_embeddings(X_me) \n",
        "\n",
        "pred = model.predict(X_me_embed)\n",
        "\n",
        "for i in range(X_me.shape[0]):\n",
        "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMh2dIInj5rL",
        "outputId": "5ef64353-4d11-4cc6-c557-c1d0aa5f7df9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "not happy ðŸ˜ž\n",
            "i adore you â¤ï¸\n",
            "i love you â¤ï¸\n",
            "funny lol ðŸ˜„\n",
            "lets play with a ball ðŸ\n",
            "food is ready ðŸ´\n",
            "not feeling happy ðŸ˜ž\n",
            "not feeling happy and funny ðŸ˜„\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9g0POHaj6eP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}